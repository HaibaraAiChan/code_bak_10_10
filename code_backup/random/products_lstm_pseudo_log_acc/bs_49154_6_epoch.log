main start at this time 1630967005.412274
before load_data step Time(s): 0.0017
load ogbn-products
-------------------------------------------------------------data = DglNodePropPredDataset(name=name)*************************** step Time(s): 1.3177
finish loading ogbn-products
-------------------------------------------------------------splitted_idx = data.get_idx_split()*************************** step Time(s): 0.2585
-------------------------------------------------------------graph, labels = data[0]*************************** step Time(s): 4.0231
tensor([[0],
        [1],
        [2],
        ...,
        [8],
        [2],
        [4]])
graph after remove self connected edges
Graph(num_nodes=2449029, num_edges=123718024,
      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float32)}
      edata_schemes={})
-------------------------------------------------------------labels = labels[:, 0]*************************** step Time(s): 0.0009
-------------------------------------------------------------graph.ndata['features'] = graph.ndata['feat']*************************** step Time(s): 0.0002
-------------------------------------------------graph.ndata['labels'] = labels****************** step Time(s): 0.0001
-------------------------------------------------train_nid, val_nid, test_nid = splitted_idx****************** step Time(s): 0.1140
-------------------------------------------------end of load ogb****************** step Time(s): 0.0114
finish constructing ogbn-products
load ogb-products time total: 5.725909471511841
#nodes: 2449029
#edges: 123718024
#classes: 47
after load_dataset step Time(s): 5.8341
after inductive else step Time(s): 0.0001
args.data_cpu
False
after label step Time(s): 4.5422
after train_g.create_formats_() step Time(s): 3.2348
after pack data step Time(s): 11.2897
Epoch 0
----main run function: start generate block_dataloader from full batch train graph


full batch graph output nodes length
196571
block_to_graph.dstdata
OUTPUT_NID.tolist()
196571

list for split-------------------------------------------------------------------------------------------
196571

-------------------------batches_nid_list ----------------------------------------------------------------
4
- -- -- --- -- -- --weights_list-- -- -- ------- -- -- -----
[0.2500572312294286, 0.2500572312294286, 0.2500572312294286, 0.24982830631171435]
after generate_random_mini_batch_seeds_list
time of batches_nid_list generation : 0.09295463562011719 sec
----main run function: block dataloader generation total spend   5.42082667350769
length of block dataloader
4
current Epoch training on CPU without block data loder Time(s): 2.3637
pseudo_mini_loss  1.2186944484710693
pseudo_mini_loss sum 4.86357307434082
Epoch 00000 | Step 00000 | Loss 1.2187 | Train Acc 0.0187 | Speed (samples/sec) 126447.2850 | GPU 4.2505 GB
		avg iteration(step) data from cpu to GPU time:231.76129532 ms
		avg iteration GPU training time:228.79592896 ms
		avg iteration (step) total cpu time:461.22193336 ms
Epoch 1
----main run function: start generate block_dataloader from full batch train graph


full batch graph output nodes length
196571
block_to_graph.dstdata
OUTPUT_NID.tolist()
196571

list for split-------------------------------------------------------------------------------------------
196571

-------------------------batches_nid_list ----------------------------------------------------------------
4
- -- -- --- -- -- --weights_list-- -- -- ------- -- -- -----
[0.2500572312294286, 0.2500572312294286, 0.2500572312294286, 0.24982830631171435]
after generate_random_mini_batch_seeds_list
time of batches_nid_list generation : 0.08323168754577637 sec
----main run function: block dataloader generation total spend   5.37420916557312
length of block dataloader
4
current Epoch training on CPU without block data loder Time(s): 1.2265
pseudo_mini_loss  1.162081003189087
pseudo_mini_loss sum 4.671788215637207
		avg iteration(step) data from cpu to GPU time:78.55897522 ms
		avg iteration GPU training time:106.37467957 ms
		avg iteration (step) total cpu time:185.80412865 ms
Epoch 2
----main run function: start generate block_dataloader from full batch train graph


full batch graph output nodes length
196571
block_to_graph.dstdata
OUTPUT_NID.tolist()
196571

list for split-------------------------------------------------------------------------------------------
196571

-------------------------batches_nid_list ----------------------------------------------------------------
4
- -- -- --- -- -- --weights_list-- -- -- ------- -- -- -----
[0.2500572312294286, 0.2500572312294286, 0.2500572312294286, 0.24982830631171435]
after generate_random_mini_batch_seeds_list
time of batches_nid_list generation : 0.09094882011413574 sec
----main run function: block dataloader generation total spend   5.367019176483154
length of block dataloader
4
current Epoch training on CPU without block data loder Time(s): 1.3262
pseudo_mini_loss  1.1148991584777832
pseudo_mini_loss sum 4.483788967132568
		avg iteration(step) data from cpu to GPU time:102.47870445 ms
		avg iteration GPU training time:108.86561775 ms
		avg iteration (step) total cpu time:212.17799187 ms
Epoch 3
----main run function: start generate block_dataloader from full batch train graph


full batch graph output nodes length
196571
block_to_graph.dstdata
OUTPUT_NID.tolist()
196571

list for split-------------------------------------------------------------------------------------------
196571

-------------------------batches_nid_list ----------------------------------------------------------------
4
- -- -- --- -- -- --weights_list-- -- -- ------- -- -- -----
[0.2500572312294286, 0.2500572312294286, 0.2500572312294286, 0.24982830631171435]
after generate_random_mini_batch_seeds_list
time of batches_nid_list generation : 0.0865774154663086 sec
----main run function: block dataloader generation total spend   5.624541282653809
length of block dataloader
4
current Epoch training on CPU without block data loder Time(s): 1.3502
pseudo_mini_loss  1.0735414028167725
pseudo_mini_loss sum 4.292034149169922
		avg iteration(step) data from cpu to GPU time:104.09390068 ms
		avg iteration GPU training time:110.54519081 ms
		avg iteration (step) total cpu time:215.52556753 ms
Epoch 4
----main run function: start generate block_dataloader from full batch train graph


full batch graph output nodes length
196571
block_to_graph.dstdata
OUTPUT_NID.tolist()
196571

list for split-------------------------------------------------------------------------------------------
196571

-------------------------batches_nid_list ----------------------------------------------------------------
4
- -- -- --- -- -- --weights_list-- -- -- ------- -- -- -----
[0.2500572312294286, 0.2500572312294286, 0.2500572312294286, 0.24982830631171435]
after generate_random_mini_batch_seeds_list
time of batches_nid_list generation : 0.0870974063873291 sec
----main run function: block dataloader generation total spend   5.684674263000488
length of block dataloader
4
current Epoch training on CPU without block data loder Time(s): 1.3164
pseudo_mini_loss  1.0240994691848755
pseudo_mini_loss sum 4.090734481811523
		avg iteration(step) data from cpu to GPU time:104.09110260 ms
		avg iteration GPU training time:106.22674370 ms
		avg iteration (step) total cpu time:211.18372679 ms
Epoch 5
----main run function: start generate block_dataloader from full batch train graph


full batch graph output nodes length
196571
block_to_graph.dstdata
OUTPUT_NID.tolist()
196571

list for split-------------------------------------------------------------------------------------------
196571

-------------------------batches_nid_list ----------------------------------------------------------------
4
- -- -- --- -- -- --weights_list-- -- -- ------- -- -- -----
[0.2500572312294286, 0.2500572312294286, 0.2500572312294286, 0.24982830631171435]
after generate_random_mini_batch_seeds_list
time of batches_nid_list generation : 0.09687352180480957 sec
----main run function: block dataloader generation total spend   5.5780417919158936
length of block dataloader
4
current Epoch training on CPU without block data loder Time(s): 1.3489
pseudo_mini_loss  0.975220799446106
pseudo_mini_loss sum 3.8712210655212402
Epoch 00005 | Step 00000 | Loss 0.9752 | Train Acc 0.1704 | Speed (samples/sec) 150082.4031 | GPU 4.2526 GB
		avg iteration(step) data from cpu to GPU time:104.23118401 ms
		avg iteration GPU training time:111.90902519 ms
		avg iteration (step) total cpu time:217.01002121 ms
	total avg iteration(step) data from cpu to GPU time:0.10372372 s
	total avg iteration GPU training time:0.10938664 s
	total avg iteration (step) total cpu time:0.21397433 s

total avg epoch training  total cpu time:1.33541709 s

total avg block generate cpu time:5.56356913 second
